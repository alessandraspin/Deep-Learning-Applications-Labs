{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cc1bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63425f",
   "metadata": {},
   "source": [
    "## Exercise 1: MLP and Residual MLP on MNIST\n",
    "Replication, on a small scale, of the ResNet paper results, demonstrating the fact that deeper networks do not guarantee more reduction in training loss (or in validation accuracy) since a degradation problem is exposed: with the network depth increasing, accuracy gets saturated and then degrades rapidly. The paper's authors address the degradation problem by introducing a deep residual learning framework, fitting identity mapping within each block.\n",
    "\n",
    "1. myMLP( ) defines a Multi Layer Perceptron with an hidden fully connected layer, a Gelu as the non-linear activation function between layers and a final logaritmic softmax to generate the output probabilities for classification task;\n",
    "\n",
    "2. ResidualMLP( ) adds in the forward function the identity mapping between the input and the last layer output, a.k.a. a skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a118dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST DataLoaders pronti.\n",
      "  - Training samples: 55000, Validation samples: 5000, Test samples: 10000\n",
      "CIFAR-10 DataLoaders pronti.\n",
      "  - Training samples: 45000, Validation samples: 5000, Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# models and dataloaders definition\n",
    "from torchvision.models import resnet18\n",
    "from src.models import MLP_2layers, MLP_3layers, ResidualMLP, myCNN\n",
    "from src.dataloader import get_cifar10_loaders, get_mnist_loaders\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_MLP_2layers = MLP_2layers().to(device)\n",
    "model_MLP_3layers = MLP_3layers().to(device)\n",
    "model_ResidualMLP = ResidualMLP().to(device)\n",
    "model_myCNN = myCNN().to(device)\n",
    "model_resnet18= resnet18(pretrained=True).to(device)\n",
    "\n",
    "mnist_train_loader, mnist_val_loader, mnist_test_loader = get_mnist_loaders(batch_size=64)\n",
    "cifar10_train_loader, cifar10_val_loader, cifar10_test_loader = get_cifar10_loaders(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45683012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860 iterations per epoch\n",
      "79 val iterations per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP_2layers:   0%|                   | 0/100 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ../DeepLearningApplications-Labs/LAB1/models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m lab1_root = os.path.dirname(os.path.abspath(\u001b[34m__file__\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;28;01melse\u001b[39;00m os.getcwd()\n\u001b[32m      6\u001b[39m save_dir = os.path.join(lab1_root, \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m train_losses_MLP_2layers, val_losses_MLP_2layers, val_accuracies_MLP_2layers, best_val_acc_MLP_2layers = trainer(model_MLP_2layers, mnist_train_loader, mnist_val_loader, device)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# model_MLP_2layers.load_state_dict(torch.load(\"models/best_MLP_2layers.pth\"))\u001b[39;00m\n\u001b[32m     10\u001b[39m model_MLP_2layers.load_state_dict(torch.load(os.path.join(save_dir, \u001b[33m\"\u001b[39m\u001b[33mbest_MLP_2layers.pth\u001b[39m\u001b[33m\"\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep-Learning-Applications-Labs/LAB1/src/trainer.py:82\u001b[39m, in \u001b[36mtrainer\u001b[39m\u001b[34m(model, dl_train, dl_val, device)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val_acc > best_val_acc:\n\u001b[32m     81\u001b[39m     best_val_acc = val_acc\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     torch.save(model.state_dict(), save_path)\n\u001b[32m     84\u001b[39m model.train()  \u001b[38;5;66;03m# returning to training mode after evaluation mode\u001b[39;00m\n\u001b[32m     85\u001b[39m scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dla2025/lib/python3.13/site-packages/torch/serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    967\u001b[39m         _save(\n\u001b[32m    968\u001b[39m             obj,\n\u001b[32m    969\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m             _disable_byteorder_record,\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dla2025/lib/python3.13/site-packages/torch/serialization.py:828\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dla2025/lib/python3.13/site-packages/torch/serialization.py:792\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    786\u001b[39m         torch._C.PyTorchFileWriter(\n\u001b[32m    787\u001b[39m             \u001b[38;5;28mself\u001b[39m.file_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m         torch._C.PyTorchFileWriter(\n\u001b[32m    793\u001b[39m             \u001b[38;5;28mself\u001b[39m.name, get_crc32_options(), _get_storage_alignment()\n\u001b[32m    794\u001b[39m         )\n\u001b[32m    795\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Parent directory ../DeepLearningApplications-Labs/LAB1/models does not exist."
     ]
    }
   ],
   "source": [
    "# training and testing the above models\n",
    "from src.trainer import trainer\n",
    "from src.tester import tester\n",
    "\n",
    "lab1_root = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "save_dir = os.path.join(lab1_root, \"models\")\n",
    "\n",
    "train_losses_MLP_2layers, val_losses_MLP_2layers, val_accuracies_MLP_2layers, best_val_acc_MLP_2layers = trainer(model_MLP_2layers, mnist_train_loader, mnist_val_loader, device)\n",
    "# model_MLP_2layers.load_state_dict(torch.load(\"models/best_MLP_2layers.pth\"))\n",
    "model_MLP_2layers.load_state_dict(torch.load(os.path.join(save_dir, \"best_MLP_2layers.pth\")))\n",
    "test_loss_MLP_2layers, test_accuracy_MLP_2layers = tester(model_MLP_2layers, mnist_test_loader, device)\n",
    "\n",
    "train_losses_MLP_3layers, val_losses_MLP_3layers, val_accuracies_MLP_3layers, best_val_acc_MLP_3layers = trainer(model_MLP_3layers, mnist_train_loader, mnist_val_loader, device)\n",
    "# model_MLP_3layers.load_state_dict(torch.load(\"models/best_MLP_3layers.pth\"))\n",
    "model_MLP_3layers.load_state_dict(torch.load(os.path.join(save_dir, \"best_MLP_3layers.pth\")))\n",
    "test_loss_MLP_3layers, test_accuracy_MLP_3layers = tester(model_MLP_3layers, mnist_test_loader, device)\n",
    "\n",
    "train_losses_ResidualMLP, val_losses_ResidualMLP, val_accuracies_ResidualMLP, best_val_acc_ResidualMLP = trainer(model_ResidualMLP, mnist_train_loader, mnist_val_loader, device)\n",
    "# model_ResidualMLP.load_state_dict(torch.load(\"models/best_ResidualMLP.pth\"))\n",
    "model_ResidualMLP.load_state_dict(torch.load(os.path.join(save_dir, \"best_ResidualMLP.pth\")))\n",
    "test_loss_ResidualMLP, test_accuracy_ResidualMLP = tester(model_ResidualMLP, mnist_test_loader, device)\n",
    "\n",
    "train_losses_myCNN, val_losses_myCNN, val_accuracies_myCNN, best_val_acc_myCNN = trainer(model_myCNN, cifar10_train_loader, cifar10_val_loader, device)\n",
    "# model_myCNN.load_state_dict(torch.load(\"models/best_myCNN.pth\"))\n",
    "model_myCNN.load_state_dict(torch.load(os.path.join(save_dir, \"best_myCNN.pth\")))\n",
    "test_loss_myCNN, test_accuracy_myCNN = tester(model_myCNN, cifar10_test_loader, device)\n",
    "\n",
    "train_losses_resnet18, val_losses_resnet18, val_accuracies_resnet18, best_val_acc_resnet18 = trainer(model_resnet18, cifar10_train_loader, cifar10_val_loader, device)\n",
    "# model_resnet18.load_state_dict(torch.load(\"models/best_resnet18.pth\"))\n",
    "model_resnet18.load_state_dict(torch.load(os.path.join(save_dir, \"best_resnet18.pth\")))\n",
    "test_loss_resnet18, test_accuracy_resnet18 = tester(model_resnet18, cifar10_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a166f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing testing results\n",
    "print(f\"MLP 2 layers - Test Loss: {test_loss_MLP_2layers:.4f}, Test Accuracy: {test_accuracy_MLP_2layers:.4f}\") \n",
    "print(f\"MLP 3 layers - Test Loss: {test_loss_MLP_3layers:.4f}, Test Accuracy: {test_accuracy_MLP_3layers:.4f}\")\n",
    "print(f\"Residual MLP - Test Loss: {test_loss_ResidualMLP:.4f}, Test Accuracy: {test_accuracy_ResidualMLP:.4f}\")\n",
    "print(f\"myCNN - Test Loss: {test_loss_myCNN:.4f}, Test Accuracy: {test_accuracy_myCNN:.4f}\")\n",
    "print(f\"ResNet18 - Test Loss: {test_loss_resnet18:.4f}, Test Accuracy: {test_accuracy_resnet18:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting training and validation performances\n",
    "from src.utils import plot_single_performance, plot_all_performances\n",
    "\n",
    "plot_single_performance(train_losses_MLP_2layers, val_losses_MLP_2layers, val_accuracies_MLP_2layers, \"MLP 2 Layers\")\n",
    "plot_single_performance(train_losses_MLP_3layers, val_losses_MLP_3layers, val_accuracies_MLP_3layers, \"MLP 3 Layers\")\n",
    "plot_single_performance(train_losses_ResidualMLP, val_losses_ResidualMLP, val_accuracies_ResidualMLP, \"Residual MLP\")\n",
    "plot_single_performance(train_losses_myCNN, val_losses_myCNN, val_accuracies_myCNN, \"myCNN\")\n",
    "plot_single_performance(train_losses_resnet18, val_losses_resnet18, val_accuracies_resnet18, \"ResNet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import plot_single_performance, plot_all_performances\n",
    "\n",
    "all_models_data = {\n",
    "    \"MLP 2 Layers\": {\n",
    "        \"train_losses\": train_losses_MLP_2layers,\n",
    "        \"val_losses\": val_losses_MLP_2layers,\n",
    "        \"val_accuracies\": val_accuracies_MLP_2layers\n",
    "    },\n",
    "    \"MLP 3 Layers\": {\n",
    "        \"train_losses\": train_losses_MLP_3layers,\n",
    "        \"val_losses\": val_losses_MLP_3layers,\n",
    "        \"val_accuracies\": val_accuracies_MLP_3layers\n",
    "    },\n",
    "    \"Residual MLP\": {\n",
    "        \"train_losses\": train_losses_ResidualMLP,\n",
    "        \"val_losses\": val_losses_ResidualMLP,\n",
    "        \"val_accuracies\": val_accuracies_ResidualMLP\n",
    "    },\n",
    "    \"myCNN\": {\n",
    "        \"train_losses\": train_losses_myCNN,\n",
    "        \"val_losses\": val_losses_myCNN,\n",
    "        \"val_accuracies\": val_accuracies_myCNN\n",
    "    },\n",
    "    \"ResNet18\": {\n",
    "        \"train_losses\": train_losses_resnet18,\n",
    "        \"val_losses\": val_losses_resnet18,\n",
    "        \"val_accuracies\": val_accuracies_resnet18\n",
    "    }\n",
    "}\n",
    "\n",
    "plot_all_performances(all_models_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
